import java.util.Set;
import java.util.regex.Pattern;
import java.io.BufferedWriter;
import java.io.FileWriter;
import java.io.IOException;



import edu.uci.ics.crawler4j.crawler.Page;
import edu.uci.ics.crawler4j.crawler.WebCrawler;
import edu.uci.ics.crawler4j.parser.BinaryParseData;
import edu.uci.ics.crawler4j.parser.HtmlParseData;
import edu.uci.ics.crawler4j.url.WebURL;


public class MyCrawler extends WebCrawler {
	//private final static Pattern FILTERS = Pattern.compile(".*(\\.(htm|html|doc|docx|pdf))$");
	private final static Pattern FILTERS = Pattern.compile(".*\\.(htm|html|doc|docx|pdf)$");
	private final static String baseUrl = "http://gould.usc.edu/";
	
	/**
	* This method receives two parameters. The first parameter is the page
	* in which we have discovered this new url and the second parameter is
	* the new url. You should implement this function to specify whether
	* the given url should be crawled or not (based on your crawling logic).
	* In this example, we are instructing the crawler to ignore urls that
	* have css, js, git, ... extensions and to only accept urls that start
	* with "http://www.viterbi.usc.edu/". In this case, we didn't need the
	* referringPage parameter to make the decision.
	*/
	
	@Override
	protected void onUnexpectedStatusCode(String urlStr, int statusCode, String contentType, String description) {
	    logger.warn("Skipping URL: {}, StatusCode: {}, {}, {}", urlStr, statusCode, contentType, description);
	    if(urlStr.startsWith(baseUrl)){
	    	try{
				BufferedWriter bw = new BufferedWriter(new FileWriter("fetch.csv",true));
				bw.append(urlStr+","+statusCode+"\n");
				bw.close();
			} catch(IOException ioe){
				ioe.printStackTrace();
			}
	    }
	    
	    try{
			BufferedWriter bw = new BufferedWriter(new FileWriter("urls.csv",true));
			bw.append(urlStr+"\n");
			bw.close();
		} catch(IOException ioe){
			ioe.printStackTrace();
		}
	}

	
	@Override
	public boolean shouldVisit(Page referringPage, WebURL url) {
		String href = url.getURL().toLowerCase();
		//System.out.println(referringPage.getWebURL().getURL() + "  "+href);
		try{
			BufferedWriter bw = new BufferedWriter(new FileWriter("urls.csv",true));
			bw.append(href+","+referringPage.getStatusCode()+"\n");
			bw.close();
		} catch(IOException ioe){
			ioe.printStackTrace();
		}
		
		if(href.startsWith(baseUrl)){
			try{
				BufferedWriter bw = new BufferedWriter(new FileWriter("fetch.csv",true));
				bw.append(href+","+referringPage.getStatusCode()+"\n");
				bw.close();
				bw = new BufferedWriter(new FileWriter("pagerankdata.csv",true));
				bw.append(referringPage.getWebURL().getURL()+","+href+"\n");
				bw.close();
			} catch(IOException ioe){
				ioe.printStackTrace();
			}
		}
		
		/*if(FILTERS.matcher(href).matches() && href.startsWith(baseUrl) && href.endsWith(".pdf")){
			System.out.println("sv   "+href);
		}*/
		
		return FILTERS.matcher(href).matches() && href.startsWith(baseUrl);
	}
	
	/**
	* This function is called when a page is fetched and ready
	* to be processed by your program.
	*/
	@Override
	public void visit(Page page) {
		String url = page.getWebURL().getURL();
		//if(url.endsWith(".pdf"))// || url.endsWith(".png") || url.endsWith(".jpg"))
		//	System.out.println("vv   "+url);
		//System.out.println(page.getContentType());
		
		if (page.getParseData() instanceof HtmlParseData) {
			HtmlParseData htmlParseData = (HtmlParseData) page.getParseData();
			//String text = htmlParseData.getText();
			String html = htmlParseData.getHtml();
			Set<WebURL> links = htmlParseData.getOutgoingUrls();
			//System.out.println("Text length: " + text.length());
			//System.out.println("Html length: " + html.length());
			//System.out.println("Number of outgoing links: " + links.size());
			//System.out.println("Status Code: "+statusCode);
			//System.out.println("Content Type: " + contentType);
			
			try {
				BufferedWriter bw = new BufferedWriter(new FileWriter("visit.csv",true));
				bw.append(url+","+html.length()+","+links.size()+","+page.getContentType()+"\n");
				bw.close();
			} catch (IOException ioe) {
				// TODO Auto-generated catch block
				ioe.printStackTrace();
			} 
		}
		
		else{
			BinaryParseData binaryParseData = (BinaryParseData) page.getParseData();
			String binary = binaryParseData.getHtml();
			Set<WebURL> links = binaryParseData.getOutgoingUrls();
			try {
				BufferedWriter bw = new BufferedWriter(new FileWriter("visit.csv",true));
				bw.append(url+","+binary.length()+","+links.size()+","+page.getContentType()+"\n");
				bw.close();
			} catch (IOException ioe) {
				// TODO Auto-generated catch block
				ioe.printStackTrace();
			} 
			
		}
	}
}
